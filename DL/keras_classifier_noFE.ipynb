{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 00:57:45.396864: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, FunctionTransformer\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and split the data\n",
    "train_origin = pd.read_csv('/Users/jaesolshin/내 드라이브/2024-2/Google ML Bootcamp2024/data/playground1/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train_origin.sample(frac=0.01, random_state = 42).set_index('id').astype(str)\n",
    "train = train_origin.set_index('id').astype(str)\n",
    "\n",
    "# 예측변수 분리 및 train, valid set 분리\n",
    "X = train.drop(['Response'], axis=1)\n",
    "y = train['Response']\n",
    "\n",
    "# 훈련 세트와 테스트 세트로 데이터 분할\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 전체 변수 타겟 인코딩\n",
    "enc = TargetEncoder()\n",
    "X_train = pd.DataFrame(enc.fit_transform(X_train, y_train), \n",
    "                       index=X_train.index, columns=X_train.columns)\n",
    "X_valid = pd.DataFrame(enc.transform(X_valid), index=X_valid.index, \n",
    "                      columns=X_valid.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의 함수\n",
    "def get_model2(meta):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(meta[\"X_shape_\"][1:]))\n",
    "    model.add(keras.layers.Dense(64, kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization()),\n",
    "    model.add(keras.layers.Dense(128, kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization()),\n",
    "    model.add(keras.layers.Dense(256, kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization()),\n",
    "    model.add(keras.layers.Dense(128, kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization()),\n",
    "    model.add(keras.layers.Dense(32, kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, kernel_initializer='he_normal', activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 학습률 스케줄러 함수 정의\n",
    "def lr_scheduler(epoch, lr):\n",
    "    decay_rate = 0.96\n",
    "    decay_step = 10\n",
    "    new_lr = lr * (decay_rate ** (epoch // decay_step))\n",
    "    print(f\"Epoch {epoch}: Learning rate is {new_lr}\")\n",
    "    return new_lr\n",
    "\n",
    "# LearningRateScheduler 콜백 설정\n",
    "lr_schedule = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "keras_model = KerasClassifier(\n",
    "    get_model2,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.AdamW(learning_rate=2e-03),\n",
    "    validation_split=0.05,\n",
    "    batch_size=128,\n",
    "    validation_batch_size=65536,\n",
    "    epochs=30,  # Increase the number of epochs for further training\n",
    "    callbacks=[lr_schedule, keras.callbacks.EarlyStopping(patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Learning rate is 0.0020000000949949026\n",
      "Epoch 1/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 10ms/step - loss: 0.2539 - val_loss: 0.2513 - learning_rate: 0.0020\n",
      "Epoch 1: Learning rate is 0.0020000000949949026\n",
      "Epoch 2/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 8ms/step - loss: 0.2515 - val_loss: 0.2510 - learning_rate: 0.0020\n",
      "Epoch 2: Learning rate is 0.0020000000949949026\n",
      "Epoch 3/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 8ms/step - loss: 0.2514 - val_loss: 0.2512 - learning_rate: 0.0020\n",
      "Epoch 3: Learning rate is 0.0020000000949949026\n",
      "Epoch 4/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m671s\u001b[0m 10ms/step - loss: 0.2509 - val_loss: 0.2513 - learning_rate: 0.0020\n",
      "Epoch 4: Learning rate is 0.0020000000949949026\n",
      "Epoch 5/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m706s\u001b[0m 10ms/step - loss: 0.2511 - val_loss: 0.2519 - learning_rate: 0.0020\n",
      "Epoch 5: Learning rate is 0.0020000000949949026\n",
      "Epoch 6/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 8ms/step - loss: 0.2510 - val_loss: 0.2515 - learning_rate: 0.0020\n",
      "Epoch 6: Learning rate is 0.0020000000949949026\n",
      "Epoch 7/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 9ms/step - loss: 0.2509 - val_loss: 0.2517 - learning_rate: 0.0020\n",
      "Epoch 7: Learning rate is 0.0020000000949949026\n",
      "Epoch 8/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m593s\u001b[0m 9ms/step - loss: 0.2512 - val_loss: 0.2511 - learning_rate: 0.0020\n",
      "Epoch 8: Learning rate is 0.0020000000949949026\n",
      "Epoch 9/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 10ms/step - loss: 0.2511 - val_loss: 0.2506 - learning_rate: 0.0020\n",
      "Epoch 9: Learning rate is 0.0020000000949949026\n",
      "Epoch 10/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m670s\u001b[0m 10ms/step - loss: 0.2511 - val_loss: 0.2513 - learning_rate: 0.0020\n",
      "Epoch 10: Learning rate is 0.0019200000911951064\n",
      "Epoch 11/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 11ms/step - loss: 0.2509 - val_loss: 0.2507 - learning_rate: 0.0019\n",
      "Epoch 11: Learning rate is 0.0018432000651955605\n",
      "Epoch 12/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 9ms/step - loss: 0.2507 - val_loss: 0.2506 - learning_rate: 0.0018\n",
      "Epoch 12: Learning rate is 0.001769472062587738\n",
      "Epoch 13/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m644s\u001b[0m 9ms/step - loss: 0.2507 - val_loss: 0.2510 - learning_rate: 0.0018\n",
      "Epoch 13: Learning rate is 0.00169869314879179\n",
      "Epoch 14/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m813s\u001b[0m 12ms/step - loss: 0.2508 - val_loss: 0.2504 - learning_rate: 0.0017\n",
      "Epoch 14: Learning rate is 0.0016307454183697699\n",
      "Epoch 15/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 10ms/step - loss: 0.2506 - val_loss: 0.2506 - learning_rate: 0.0016\n",
      "Epoch 15: Learning rate is 0.001565515547990799\n",
      "Epoch 16/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 9ms/step - loss: 0.2509 - val_loss: 0.2524 - learning_rate: 0.0016\n",
      "Epoch 16: Learning rate is 0.0015028949081897734\n",
      "Epoch 17/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5286s\u001b[0m 77ms/step - loss: 0.2510 - val_loss: 0.2505 - learning_rate: 0.0015\n",
      "Epoch 17: Learning rate is 0.001442779116332531\n",
      "Epoch 18/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1936s\u001b[0m 28ms/step - loss: 0.2506 - val_loss: 0.2505 - learning_rate: 0.0014\n",
      "Epoch 18: Learning rate is 0.0013850679248571395\n",
      "Epoch 19/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4252s\u001b[0m 62ms/step - loss: 0.2512 - val_loss: 0.2521 - learning_rate: 0.0014\n",
      "Epoch 19: Learning rate is 0.001329665221273899\n",
      "Epoch 20/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7474s\u001b[0m 109ms/step - loss: 0.2506 - val_loss: 0.2521 - learning_rate: 0.0013\n",
      "Epoch 20: Learning rate is 0.0012254194378852844\n",
      "Epoch 21/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3403s\u001b[0m 50ms/step - loss: 0.2507 - val_loss: 0.2508 - learning_rate: 0.0012\n",
      "Epoch 21: Learning rate is 0.0011293465733528136\n",
      "Epoch 22/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1291s\u001b[0m 18ms/step - loss: 0.2506 - val_loss: 0.2503 - learning_rate: 0.0011\n",
      "Epoch 22: Learning rate is 0.0010408057808876038\n",
      "Epoch 23/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m765s\u001b[0m 11ms/step - loss: 0.2504 - val_loss: 0.2501 - learning_rate: 0.0010\n",
      "Epoch 23: Learning rate is 0.0009592066526412964\n",
      "Epoch 24/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m702s\u001b[0m 10ms/step - loss: 0.2504 - val_loss: 0.2508 - learning_rate: 9.5921e-04\n",
      "Epoch 24: Learning rate is 0.0008840048611164093\n",
      "Epoch 25/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 10ms/step - loss: 0.2503 - val_loss: 0.2508 - learning_rate: 8.8400e-04\n",
      "Epoch 25: Learning rate is 0.0008146988868713379\n",
      "Epoch 26/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m612s\u001b[0m 9ms/step - loss: 0.2502 - val_loss: 0.2500 - learning_rate: 8.1470e-04\n",
      "Epoch 26: Learning rate is 0.0007508264780044556\n",
      "Epoch 27/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 9ms/step - loss: 0.2504 - val_loss: 0.2505 - learning_rate: 7.5083e-04\n",
      "Epoch 27: Learning rate is 0.0006919616997241974\n",
      "Epoch 28/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 9ms/step - loss: 0.2501 - val_loss: 0.2502 - learning_rate: 6.9196e-04\n",
      "Epoch 28: Learning rate is 0.000637711876630783\n",
      "Epoch 29/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 8ms/step - loss: 0.2500 - val_loss: 0.2499 - learning_rate: 6.3771e-04\n",
      "Epoch 29: Learning rate is 0.0005877152860164642\n",
      "Epoch 30/30\n",
      "\u001b[1m68310/68310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 9ms/step - loss: 0.2502 - val_loss: 0.2510 - learning_rate: 5.8772e-04\n",
      "\u001b[1m17977/17977\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 5ms/step\n",
      "# AUC: 0.88289\n"
     ]
    }
   ],
   "source": [
    "# Execute the pipeline and measure the auc score\n",
    "keras_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = keras_model.predict_proba(X_valid)[:, 1]\n",
    "print(f\"# AUC: {roc_auc_score(y_valid, y_pred):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m59921/59921\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 4ms/step\n",
      "         id  Response\n",
      "0  11504798  0.003773\n",
      "1  11504799  0.556605\n",
      "2  11504800  0.261816\n",
      "3  11504801  0.000034\n",
      "4  11504802  0.137380\n",
      "Predictions saved to 'keras_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "#test 데이터 로드\n",
    "test_origin = pd.read_csv('/Users/jaesolshin/내 드라이브/2024-2/Google ML Bootcamp2024/data/playground1/test.csv')\n",
    "\n",
    "#인덱스 제외\n",
    "X_test = test_origin.set_index('id').astype(str)\n",
    "\n",
    "# 변수 타겟 인코딩\n",
    "X_test = pd.DataFrame(enc.transform(X_test), index=X_test.index, \n",
    "                      columns=X_test.columns)\n",
    "\n",
    "# 예측 생성\n",
    "y_test_pred = keras_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# 'id'와 'Response' 열이 있는 DataFrame 생성\n",
    "submission = pd.DataFrame({'id': X_test.index, 'Response': y_test_pred})\n",
    "print(submission.head())\n",
    "\n",
    "# 예측을 CSV 파일로 저장\n",
    "submission .to_csv('keras_predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'keras_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11504798</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11504799</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11504800</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11504801</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11504802</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  Response\n",
       "0  11504798       0.5\n",
       "1  11504799       0.5\n",
       "2  11504800       0.5\n",
       "3  11504801       0.5\n",
       "4  11504802       0.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample_submission 데이터 로드\n",
    "sample = pd.read_csv('/Users/jaesolshin/내 드라이브/2024-2/Google ML Bootcamp2024/data/playground1/sample_submission.csv')\n",
    "sample.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
