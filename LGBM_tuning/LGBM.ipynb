{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from category_encoders import TargetEncoder\n",
    "from tqdm import tqdm\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Read the data\n",
    "train_origin = pd.read_csv('/Users/jaesolshin/내 드라이브/2024-2/Google ML Bootcamp2024/data/playground1/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 샘플링\n",
    "train = train_origin.sample(frac=0.01, random_state = 42)\n",
    "\n",
    "# 예측에 필요 없는 'id'와 'Annual_Premium' 변수를 드롭\n",
    "train = train.drop(columns=['id'])\n",
    "\n",
    "# 범주형 변수 인코딩\n",
    "def encoding(train):\n",
    "    gender_mapping = {'Male': 0, 'Female': 1}\n",
    "    vehicle_age_mapping = {'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2}\n",
    "    vehicle_damage_mapping = {'No': 0, 'Yes': 1}\n",
    "\n",
    "    train['Gender'] = train['Gender'].map(gender_mapping)\n",
    "    train['Vehicle_Age'] = train['Vehicle_Age'].map(vehicle_age_mapping)\n",
    "    train['Vehicle_Damage'] = train['Vehicle_Damage'].map(vehicle_damage_mapping)\n",
    "\n",
    "    return train\n",
    "\n",
    "train = encoding(train)\n",
    "\n",
    "#수치형 변수: Annual, Region_Code, Annual_Premium, Policy_Sales_Channel, Vintage -> normalize\n",
    "scaler = MinMaxScaler()\n",
    "num_columns = ['Age', 'Region_Code', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']\n",
    "train[num_columns] = scaler.fit_transform(train[num_columns])\n",
    "\n",
    "# XGBoost에서 발생하는 문제 해결\n",
    "train.columns = train.columns.str.replace('[', '').str.replace(']', '').str.replace('<', '')\n",
    "\n",
    "# 예측변수 분리 및 train, valid set 분리\n",
    "X = train.drop(['Response'], axis=1)\n",
    "y = train['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(model, X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state =42)\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "\n",
    "    for fold, (train_index, valid_index) in enumerate(tqdm(skf.split(X_train, y_train), total=skf.get_n_splits(), desc=\"Folds\"), 1):\n",
    "        X_skf_train, X_skf_valid = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "        y_skf_train, y_skf_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "\n",
    "        model.fit(X_skf_train, y_skf_train)\n",
    "\n",
    "        train_preds = model.predict_proba(X_skf_train)[:, 1]\n",
    "        train_auc = roc_auc_score(y_skf_train, train_preds)\n",
    "        train_scores.append(train_auc)\n",
    "\n",
    "        valid_preds = model.predict_proba(X_skf_valid)[:, 1]\n",
    "        valid_auc = roc_auc_score(y_skf_valid, valid_preds)\n",
    "        valid_scores.append(valid_auc)\n",
    "\n",
    "        print(f'Fold {fold}: Train ROC AUC: {train_auc:.4f}, Validation ROC AUC: {valid_auc:.4f}')\n",
    "\n",
    "    print(f'Average Train ROC AUC: {sum(train_scores)/len(train_scores):.4f}')\n",
    "    print(f'Average Validation ROC AUC: {sum(valid_scores)/len(valid_scores):.4f}')\n",
    "\n",
    "    test_preds = model.predict_proba(X_test)[:, 1]\n",
    "    test_auc = roc_auc_score(y_test, test_preds)\n",
    "    print(f'Test ROC AUC: {test_auc:.4f}')\n",
    "\n",
    "\n",
    "    return train_scores, valid_scores, test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 9054, number of negative: 64576\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 73630, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122966 -> initscore=-1.964636\n",
      "[LightGBM] [Info] Start training from score -1.964636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  20%|██        | 1/5 [00:03<00:15,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train ROC AUC: 0.8873, Validation ROC AUC: 0.8659\n",
      "[LightGBM] [Info] Number of positive: 9054, number of negative: 64576\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 716\n",
      "[LightGBM] [Info] Number of data points in the train set: 73630, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122966 -> initscore=-1.964636\n",
      "[LightGBM] [Info] Start training from score -1.964636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  40%|████      | 2/5 [00:05<00:08,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: Train ROC AUC: 0.8931, Validation ROC AUC: 0.8621\n",
      "[LightGBM] [Info] Number of positive: 9054, number of negative: 64576\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 73630, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122966 -> initscore=-1.964636\n",
      "[LightGBM] [Info] Start training from score -1.964636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  60%|██████    | 3/5 [00:07<00:04,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: Train ROC AUC: 0.8920, Validation ROC AUC: 0.8688\n",
      "[LightGBM] [Info] Number of positive: 9055, number of negative: 64576\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 73631, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122978 -> initscore=-1.964526\n",
      "[LightGBM] [Info] Start training from score -1.964526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  80%|████████  | 4/5 [00:09<00:02,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: Train ROC AUC: 0.8910, Validation ROC AUC: 0.8598\n",
      "[LightGBM] [Info] Number of positive: 9055, number of negative: 64576\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 712\n",
      "[LightGBM] [Info] Number of data points in the train set: 73631, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122978 -> initscore=-1.964526\n",
      "[LightGBM] [Info] Start training from score -1.964526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 100%|██████████| 5/5 [00:12<00:00,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: Train ROC AUC: 0.8926, Validation ROC AUC: 0.8607\n",
      "Average Train ROC AUC: 0.8912\n",
      "Average Validation ROC AUC: 0.8634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.8667\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "print(\"\\nLightGBM:\")\n",
    "lgbm_model = LGBMClassifier(random_state=42)\n",
    "lgbm_train_scores, lgbm_valid_scores, lgbm_test_auc = modeling(lgbm_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# 데이터 샘플링\n",
    "train = train_origin.sample(frac=0.01, random_state = 42)\n",
    "\n",
    "# 예측에 필요 없는 'id'와 'Annual_Premium' 변수를 드롭\n",
    "train = train.drop(columns=['id'])\n",
    "\n",
    "# 범주형 변수 인코딩\n",
    "def encoding(train):\n",
    "    gender_mapping = {'Male': 0, 'Female': 1}\n",
    "    vehicle_age_mapping = {'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2}\n",
    "    vehicle_damage_mapping = {'No': 0, 'Yes': 1}\n",
    "\n",
    "    train['Gender'] = train['Gender'].map(gender_mapping)\n",
    "    train['Vehicle_Age'] = train['Vehicle_Age'].map(vehicle_age_mapping)\n",
    "    train['Vehicle_Damage'] = train['Vehicle_Damage'].map(vehicle_damage_mapping)\n",
    "\n",
    "    return train\n",
    "\n",
    "train = encoding(train)\n",
    "\n",
    "# 범주형 변수 타겟 인코딩\n",
    "cat_columns = ['Region_Code', 'Policy_Sales_Channel', 'Vintage']\n",
    "train.loc[:,cat_columns] = train.loc[:,cat_columns].astype('category')\n",
    "\n",
    "target_encoder = TargetEncoder()\n",
    "train[cat_columns] = target_encoder.fit_transform(train[cat_columns],train['Response'])\n",
    "\n",
    "#수치형 변수+타겟인코딩 변수\n",
    "scaler = MinMaxScaler()\n",
    "num_columns = ['Age', 'Annual_Premium', 'Region_Code', 'Policy_Sales_Channel', 'Vintage']\n",
    "train[num_columns] = scaler.fit_transform(train[num_columns])\n",
    "\n",
    "\n",
    "# XGBoost에서 발생하는 문제 해결\n",
    "train.columns = train.columns.str.replace('[', '').str.replace(']', '').str.replace('<', '')\n",
    "\n",
    "# 예측변수 분리 및 train, valid set 분리\n",
    "X = train.drop(['Response'], axis=1)\n",
    "y = train['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 9054, number of negative: 64576\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 705\n",
      "[LightGBM] [Info] Number of data points in the train set: 73630, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122966 -> initscore=-1.964636\n",
      "[LightGBM] [Info] Start training from score -1.964636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  20%|██        | 1/5 [00:02<00:11,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train ROC AUC: 0.8950, Validation ROC AUC: 0.8734\n",
      "[LightGBM] [Info] Number of positive: 9054, number of negative: 64576\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 709\n",
      "[LightGBM] [Info] Number of data points in the train set: 73630, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122966 -> initscore=-1.964636\n",
      "[LightGBM] [Info] Start training from score -1.964636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  40%|████      | 2/5 [00:04<00:06,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: Train ROC AUC: 0.8974, Validation ROC AUC: 0.8711\n",
      "[LightGBM] [Info] Number of positive: 9054, number of negative: 64576\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 707\n",
      "[LightGBM] [Info] Number of data points in the train set: 73630, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122966 -> initscore=-1.964636\n",
      "[LightGBM] [Info] Start training from score -1.964636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  60%|██████    | 3/5 [00:06<00:03,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: Train ROC AUC: 0.8942, Validation ROC AUC: 0.8775\n",
      "[LightGBM] [Info] Number of positive: 9055, number of negative: 64576\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 705\n",
      "[LightGBM] [Info] Number of data points in the train set: 73631, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122978 -> initscore=-1.964526\n",
      "[LightGBM] [Info] Start training from score -1.964526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  80%|████████  | 4/5 [00:08<00:02,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: Train ROC AUC: 0.8974, Validation ROC AUC: 0.8692\n",
      "[LightGBM] [Info] Number of positive: 9055, number of negative: 64576\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 706\n",
      "[LightGBM] [Info] Number of data points in the train set: 73631, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122978 -> initscore=-1.964526\n",
      "[LightGBM] [Info] Start training from score -1.964526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 100%|██████████| 5/5 [00:10<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: Train ROC AUC: 0.8970, Validation ROC AUC: 0.8706\n",
      "Average Train ROC AUC: 0.8962\n",
      "Average Validation ROC AUC: 0.8724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.8772\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "lgbm_model = LGBMClassifier(random_state=42)\n",
    "print(\"\\nLightGBM:\")\n",
    "lgbm_train_scores, lgbm_valid_scores, lgbm_test_auc = modeling(lgbm_model, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
