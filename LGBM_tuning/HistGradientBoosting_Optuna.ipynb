{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from lightgbm import LGBMClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Read the data\n",
    "train_origin = pd.read_csv('/Users/jaesolshin/내 드라이브/2024-2/Google ML Bootcamp2024/data/playground1/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 샘플링\n",
    "train = train_origin.set_index('id').astype(str)\n",
    "\n",
    "# 예측변수 분리 및 train, valid set 분리\n",
    "X = train.drop(['Response'], axis=1)\n",
    "y = train['Response'].astype(float)\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 타겟 인코딩\n",
    "enc = TargetEncoder()\n",
    "X_train = pd.DataFrame(enc.fit_transform(X_train, y_train), index=X_train.index, columns=X_train.columns)\n",
    "X_valid = pd.DataFrame(enc.transform(X_valid), index=X_valid.index, columns=X_valid.columns)\n",
    "\n",
    "# 숫자형 데이터로 변환\n",
    "X_train = X_train.astype(float)\n",
    "X_valid = X_valid.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Optuna 로깅 레벨 설정\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# 목적 함수 정의\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n",
    "        'max_iter': trial.suggest_int('max_iter', 100, 5000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 12),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 100),\n",
    "        'max_bins': trial.suggest_int('max_bins', 32, 255),\n",
    "        'verbose': 1\n",
    "    }\n",
    "    model = HistGradientBoostingClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict_proba(X_valid)[:, 1]\n",
    "    score = roc_auc_score(y_valid, y_pred)\n",
    "    return score\n",
    "\n",
    "# Optuna 스터디 생성 및 최적화 실행\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best parameters found by Optuna:\", study.best_params)\n",
    "print(\"Best ROC AUC score found by Optuna:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(model, X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state =42)\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "\n",
    "    for fold, (train_index, valid_index) in enumerate(tqdm(skf.split(X_train, y_train), total=skf.get_n_splits(), desc=\"Folds\"), 1):\n",
    "        X_skf_train, X_skf_valid = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "        y_skf_train, y_skf_valid = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "\n",
    "        model.fit(X_skf_train, y_skf_train)\n",
    "\n",
    "        train_preds = model.predict_proba(X_skf_train)[:, 1]\n",
    "        train_auc = roc_auc_score(y_skf_train, train_preds)\n",
    "        train_scores.append(train_auc)\n",
    "\n",
    "        valid_preds = model.predict_proba(X_skf_valid)[:, 1]\n",
    "        valid_auc = roc_auc_score(y_skf_valid, valid_preds)\n",
    "        valid_scores.append(valid_auc)\n",
    "\n",
    "        print(f'Fold {fold}: Train ROC AUC: {train_auc:.4f}, Validation ROC AUC: {valid_auc:.4f}')\n",
    "\n",
    "    print(f'Average Train ROC AUC: {sum(train_scores)/len(train_scores):.4f}')\n",
    "    print(f'Average Validation ROC AUC: {sum(valid_scores)/len(valid_scores):.4f}')\n",
    "\n",
    "    test_preds = model.predict_proba(X_test)[:, 1]\n",
    "    test_auc = roc_auc_score(y_test, test_preds)\n",
    "    print(f'Test ROC AUC: {test_auc:.4f}')\n",
    "\n",
    "\n",
    "    return train_scores, valid_scores, test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HistGradientBoosting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  20%|██        | 1/5 [00:06<00:25,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train ROC AUC: 0.8814, Validation ROC AUC: 0.8639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  40%|████      | 2/5 [00:12<00:19,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: Train ROC AUC: 0.8828, Validation ROC AUC: 0.8605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  60%|██████    | 3/5 [00:22<00:15,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: Train ROC AUC: 0.8799, Validation ROC AUC: 0.8637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds:  80%|████████  | 4/5 [00:28<00:07,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: Train ROC AUC: 0.8775, Validation ROC AUC: 0.8611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Folds: 100%|██████████| 5/5 [00:36<00:00,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: Train ROC AUC: 0.8820, Validation ROC AUC: 0.8631\n",
      "Average Train ROC AUC: 0.8807\n",
      "Average Validation ROC AUC: 0.8625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.8607\n"
     ]
    }
   ],
   "source": [
    "#HistGBR: 0.8768\n",
    "print(\"\\nHistGradientBoosting:\")\n",
    "hist_param = {'learning_rate': 0.12004570044073418, 'max_iter': 833, 'max_depth': 2, 'min_samples_leaf': 35, 'max_bins': 222}\n",
    "hist_model = HistGradientBoostingClassifier(**hist_param, random_state=42)\n",
    "lgbm_train_scores, lgbm_valid_scores, lgbm_test_auc = modeling(hist_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM : 0.8776\n",
    "print(\"\\nLightGBM:\")\n",
    "best_param = {'lambda_l1': 0.1, 'lambda_l2': 0.1, 'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 100, 'num_leaves': 20, 'verbose':1}\n",
    "lgbm_model = LGBMClassifier(**best_param, random_state=42)\n",
    "lgbm_train_scores, lgbm_valid_scores, lgbm_test_auc = modeling(lgbm_model, X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
