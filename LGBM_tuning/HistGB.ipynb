{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Read the data\n",
    "train_origin = pd.read_csv('/Users/jaesolshin/내 드라이브/2024-2/Google ML Bootcamp2024/data/playground1/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 샘플링\n",
    "train = train_origin.set_index('id').astype(str)\n",
    "\n",
    "# 예측변수 분리 및 train, valid set 분리\n",
    "X = train.drop(['Response'], axis=1)\n",
    "y = train['Response'].astype(float)\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.002, stratify=y, random_state=42)\n",
    "\n",
    "# 타겟 인코딩\n",
    "enc = TargetEncoder()\n",
    "enc.fit(X_train, y_train) # 학습 데이터로 인코더 학습\n",
    "X_train = pd.DataFrame(enc.transform(X_train), index=X_train.index, columns=X_train.columns)\n",
    "X_valid = pd.DataFrame(enc.transform(X_valid), index=X_valid.index, columns=X_valid.columns)\n",
    "X_train = X_train.astype(float)\n",
    "X_valid = X_valid.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "def modeling(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    valid_preds = model.predict_proba(X_valid)[:, 1]\n",
    "    valid_auc = roc_auc_score(y_valid, valid_preds)\n",
    "    print(\"ROC AUC:\", valid_auc)\n",
    "\n",
    "    results.append({\"ROC AUC\":valid_auc,\"valid_preds\":valid_preds})\n",
    "    return valid_auc, valid_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HistGradientBoosting:\n",
      "ROC AUC: 0.8900060585472794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8900060585472794,\n",
       " array([1.38756266e-01, 4.49229271e-05, 5.62528411e-05, ...,\n",
       "        1.83003008e-01, 6.08986839e-04, 4.21196436e-05]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HistGBR: 0.8900\n",
    "print(\"\\nHistGradientBoosting:\")\n",
    "hist_param = {'learning_rate': 0.12, 'max_iter': 3000, 'max_depth': 12, 'min_samples_leaf': 30, 'max_bins': 220}\n",
    "hist_model = HistGradientBoostingClassifier(**hist_param, random_state=42)\n",
    "modeling(hist_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM:\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Info] Number of positive: 1412229, number of negative: 10069559\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.314070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 737\n",
      "[LightGBM] [Info] Number of data points in the train set: 11481788, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122997 -> initscore=-1.964348\n",
      "[LightGBM] [Info] Start training from score -1.964348\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "ROC AUC: 0.8914351402746308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8914351402746308,\n",
       " array([1.32680182e-01, 3.38994506e-05, 1.14102427e-04, ...,\n",
       "        1.86653755e-01, 6.34865037e-04, 3.06604577e-05]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LightGBM : 0.8776\n",
    "print(\"\\nLightGBM:\")\n",
    "best_param = {'lambda_l1': 0.1, 'lambda_l2': 0.1, 'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 3000, 'num_leaves': 20, 'verbose':1}\n",
    "lgbm_model = LGBMClassifier(**best_param, random_state=42)\n",
    "modeling(lgbm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost:\n",
      "ROC AUC: 0.8906290995878086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8906290995878086,\n",
       " array([1.4129114e-01, 4.1033691e-05, 4.7287918e-05, ..., 2.1139917e-01,\n",
       "        1.5866993e-03, 3.3784359e-05], dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost\n",
    "print(\"\\nXGBoost:\")\n",
    "xgb_param = {'n_estimators': 50, 'max_depth': 12, 'eval_metric':'logloss'}\n",
    "xgb_model = XGBClassifier(**xgb_param, random_state=42)\n",
    "modeling(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost:\n",
      "ROC AUC: 0.8917800397132521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8917800397132521,\n",
       " array([1.26874079e-01, 2.07202762e-05, 1.57144489e-04, ...,\n",
       "        1.85613321e-01, 1.12444493e-03, 3.87741203e-05]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CatBoost\n",
    "print(\"\\nCatBoost:\")\n",
    "cat_param = { 'loss_function': 'Logloss', 'eval_metric': 'AUC', 'class_names': [0, 1], 'learning_rate': 0.075, 'iterations': 3000, 'depth': 9, 'random_strength': 0, 'l2_leaf_reg': 0.5, 'max_leaves': 512, 'fold_permutation_block': 64, 'allow_writing_files': False, 'verbose':0}\n",
    "cat_model = CatBoostClassifier(**cat_param, random_state=42)\n",
    "modeling(cat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test 데이터 로드\n",
    "test_origin = pd.read_csv('/Users/jaesolshin/내 드라이브/2024-2/Google ML Bootcamp2024/data/playground1/test.csv')\n",
    "X_test = test_origin.set_index('id').astype(str)\n",
    "X_test = pd.DataFrame(enc.transform(X_test), index=X_test.index, columns=X_test.columns)\n",
    "X_test = X_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but HistGradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'hist_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# 예측 생성\n",
    "y_test_pred = hist_model.predict_proba(X_test.values)[:,1]\n",
    "submission = pd.DataFrame({'id': X_test.index, 'Response': y_test_pred})\n",
    "submission.to_csv('hist_predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'hist_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    {'model':hist_model, 'name':'hist_model'}, \n",
    "    {'model':lgbm_model, 'name':'lgbm_model'},\n",
    "    {'model':xgb_model, 'name':'xgb_model'},\n",
    "    {'model':cat_model, 'name':'cat_model'}\n",
    "]\n",
    "\n",
    "sub_results = []\n",
    "\n",
    "for clf in classifiers:\n",
    "    model = clf['model']\n",
    "    name = clf['name']\n",
    "\n",
    "    # 예측 생성\n",
    "    y_test_pred = model.predict_proba(X_test)[:,1]\n",
    "    clf['preds'] = y_test_pred\n",
    "\n",
    "    # 'id'와 'Response' 열이 있는 DataFrame 생성\n",
    "    submission = pd.DataFrame({'id': X_test.index, 'Response': y_test_pred})\n",
    "    \n",
    "    # 예측을 CSV 파일로 저장\n",
    "    submission.to_csv(f'{name}_predictions.csv', index=False)\n",
    "    print(f\"Predictions saved to '{name}_predictions.csv'\")\n",
    "\n",
    "\n",
    "# 앙상블 예측 생성\n",
    "ensemble_pred = np.mean([clf['preds'] for clf in classifiers], axis=0)\n",
    "submission = pd.DataFrame({'id': X_test.index, 'Response': ensemble_pred})\n",
    "\n",
    "# 예측을 CSV 파일로 저장\n",
    "submission.to_csv('ensemble_predictions.csv', index=False)\n",
    "print(\"Predictions saved to 'ensemble_predictions.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
