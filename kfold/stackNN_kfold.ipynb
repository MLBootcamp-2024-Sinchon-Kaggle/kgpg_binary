{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 01:50:52.212442: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "train = pd.read_csv('/Users/jaesolshin/내 드라이브/2024-2/Google ML Bootcamp2024/data/playground1/train.csv')\n",
    "train = train.sample(frac=0.01, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 범주형 변수를 팩터로 변환 (카테고리형)\n",
    "train.iloc[:,[1,3,4,5,6,7,9]] = train.iloc[:,[1,3,4,5,6,7,9]].astype('category')\n",
    "\n",
    "# 최소-최대 정규화 (Min-Max 스케일링)\n",
    "scaler = StandardScaler()\n",
    "train.iloc[:,[2,8,10]] = scaler.fit_transform(train.iloc[:,[2,8,10]])\n",
    "\n",
    "# 이분변수 생성: \"Annual_Premium\" == 2630.0 인 경우\n",
    "train['Annual_Premium_Binary'] = (train['Annual_Premium'] == 2630.0).astype('category')\n",
    "\n",
    "# 로그 변환된 \"Annual_Premium\" 변수 생성\n",
    "train['Annual_Premium_Log'] = np.where(train['Annual_Premium'] > 0, np.log1p(train['Annual_Premium']), 0)\n",
    "\n",
    "# 예측에 필요 없는 'id'와 'Annual_Premium' 변수를 드롭\n",
    "train = train.drop(columns=['id', 'Annual_Premium'])\n",
    "\n",
    "# 원-핫 인코딩 (One-Hot Encoding)\n",
    "category_columns = ['Gender', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Policy_Sales_Channel', 'Annual_Premium_Binary']\n",
    "train = pd.get_dummies(train, columns=category_columns, drop_first=True, dtype=int)\n",
    "\n",
    "# XGBoost에서 발생하는 문제 해결\n",
    "train.columns = train.columns.str.replace('[', '').str.replace(']', '').str.replace('<', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 리스트\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('CatBoost', CatBoostClassifier(random_state=42, verbose=0)),\n",
    "    ('LightGBM', LGBMClassifier(random_state=42)),\n",
    "    ('XGBoost', XGBClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "# 평가 지표 계산 함수\n",
    "def evaluate_model(y_true, y_pred, y_proba):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    TP = conf_matrix[1, 1]\n",
    "    FN = conf_matrix[1, 0]\n",
    "    TN = conf_matrix[0, 0]\n",
    "    FP = conf_matrix[0, 1]\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "    roc_auc = roc_auc_score(y_true, y_proba)\n",
    "\n",
    "    return {\n",
    "        'Confusion Matrix': conf_matrix.tolist(),\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Positive Recall': recall,\n",
    "        'Specificity': specificity,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': roc_auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression: 5it [00:29,  5.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression ROC AUC: 0.8508000485942548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Random Forest: 5it [05:31, 66.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest ROC AUC: 0.8365779567639171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CatBoost: 5it [07:47, 93.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost ROC AUC: 0.8661055425228263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 11313, number of negative: 80725\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 789\n",
      "[LightGBM] [Info] Number of data points in the train set: 92038, number of used features: 115\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122917 -> initscore=-1.965096\n",
      "[LightGBM] [Info] Start training from score -1.965096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM: 1it [00:08,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 11313, number of negative: 80725\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 800\n",
      "[LightGBM] [Info] Number of data points in the train set: 92038, number of used features: 116\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122917 -> initscore=-1.965096\n",
      "[LightGBM] [Info] Start training from score -1.965096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM: 2it [00:18,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 11312, number of negative: 80726\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 792\n",
      "[LightGBM] [Info] Number of data points in the train set: 92038, number of used features: 116\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122906 -> initscore=-1.965197\n",
      "[LightGBM] [Info] Start training from score -1.965197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM: 3it [00:39, 14.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 11313, number of negative: 80726\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 92039, number of used features: 117\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122915 -> initscore=-1.965108\n",
      "[LightGBM] [Info] Start training from score -1.965108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM: 4it [01:00, 17.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 11313, number of negative: 80726\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 802\n",
      "[LightGBM] [Info] Number of data points in the train set: 92039, number of used features: 117\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122915 -> initscore=-1.965108\n",
      "[LightGBM] [Info] Start training from score -1.965108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM: 5it [01:11, 14.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM ROC AUC: 0.8648873790457765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training XGBoost: 5it [02:24, 28.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost ROC AUC: 0.8641579637975969\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증 설정\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "X = train.drop(columns=['Response'])\n",
    "y = train['Response']\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "results = []\n",
    "stacked_predictions = np.zeros((X.shape[0], len(models)))\n",
    "model_roc_aucs = {}\n",
    "\n",
    "# 각 모델 학습 및 평가\n",
    "for model_idx, (name, model) in enumerate(models):\n",
    "    fold_probas = np.zeros(X.shape[0])\n",
    "    for train_index, valid_index in tqdm(skf.split(X, y), desc=f\"Training {name}\"):\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # 예측\n",
    "        valid_y_proba = model.predict_proba(X_valid)[:, 1]  # 양성 클래스의 확률만 저장\n",
    "        stacked_predictions[valid_index, model_idx] = valid_y_proba\n",
    "        fold_probas[valid_index] = valid_y_proba\n",
    "\n",
    "    # 각 모델의 ROC AUC 점수 계산\n",
    "    roc_auc = roc_auc_score(y, fold_probas)\n",
    "    model_roc_aucs[name] = roc_auc\n",
    "    print(f'{name} ROC AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/jaesolshin/Documents/GitHub/kgpg_binary/kfold/models/stacked_predictions_20240722_022105.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "#모델 저장\n",
    "filepath1 = os.path.join(models_dir, \"models.joblib\")\n",
    "filepath2 = os.path.join(models_dir, \"stacked_predictions.joblib\")\n",
    "\n",
    "joblib.dump(models, filepath1)\n",
    "joblib.dump(stacked_predictions, filepath2)\n",
    "\n",
    "#백업 저장\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "models_dir = os.path.join(current_dir, \"models\")\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "filepath1 = os.path.join(models_dir, f\"models_{timestamp}.joblib\")\n",
    "filepath2 = os.path.join(models_dir, f\"stacked_predictions_{timestamp}.joblib\")\n",
    "\n",
    "joblib.dump(models, filepath1)\n",
    "joblib.dump(stacked_predictions, filepath2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서부터 저장된 모델로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "#모델 경로\n",
    "filepath1 = os.path.join(models_dir, \"models.joblib\")\n",
    "filepath2 = os.path.join(models_dir, \"stacked_predictions.joblib\")\n",
    "\n",
    "models = joblib.load(filepath1)\n",
    "stacked_predictions = joblib.load(filepath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model ROC AUC Scores:\n",
      "Logistic Regression: 0.8508000485942548\n",
      "Random Forest: 0.8365779567639171\n",
      "CatBoost: 0.8661055425228263\n",
      "LightGBM: 0.8648873790457765\n",
      "XGBoost: 0.8641579637975969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fx/7qldcfl92nb_g9hqp_lrssxm0000gn/T/ipykernel_60648/2888148930.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, new_result], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns=['name', 'roc_auc'])\n",
    "\n",
    "print(\"\\nModel ROC AUC Scores:\")\n",
    "for model_name, auc_score in model_roc_aucs.items():\n",
    "    new_result = pd.DataFrame([{'name': model_name, 'roc_auc': auc_score}])\n",
    "    results_df = pd.concat([results_df, new_result], ignore_index=True)\n",
    "    print(f\"{model_name}: {auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - AUC: 0.6898 - loss: 0.4241\n",
      "Epoch 2/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 7ms/step - AUC: 0.8637 - loss: 0.2762\n",
      "Epoch 3/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - AUC: 0.8666 - loss: 0.2711\n",
      "Epoch 4/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - AUC: 0.8641 - loss: 0.2644\n",
      "Epoch 5/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - AUC: 0.8640 - loss: 0.2648\n",
      "Epoch 6/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - AUC: 0.8649 - loss: 0.2644\n",
      "Epoch 7/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - AUC: 0.8668 - loss: 0.2632\n",
      "Epoch 8/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 8ms/step - AUC: 0.8659 - loss: 0.2604\n",
      "Epoch 9/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 7ms/step - AUC: 0.8668 - loss: 0.2608\n",
      "Epoch 10/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 7ms/step - AUC: 0.8670 - loss: 0.2619\n",
      "Epoch 11/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - AUC: 0.8667 - loss: 0.2593\n",
      "Epoch 12/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - AUC: 0.8653 - loss: 0.2612\n",
      "Epoch 13/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - AUC: 0.8665 - loss: 0.2614\n",
      "Epoch 14/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - AUC: 0.8662 - loss: 0.2598\n",
      "Epoch 15/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7ms/step - AUC: 0.8660 - loss: 0.2610\n",
      "Epoch 16/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - AUC: 0.8647 - loss: 0.2622\n",
      "Epoch 17/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 7ms/step - AUC: 0.8656 - loss: 0.2619\n",
      "Epoch 18/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8ms/step - AUC: 0.8658 - loss: 0.2612\n",
      "Epoch 19/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 8ms/step - AUC: 0.8670 - loss: 0.2607\n",
      "Epoch 20/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - AUC: 0.8663 - loss: 0.2637\n",
      "Epoch 21/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 6ms/step - AUC: 0.8650 - loss: 0.2613\n",
      "Epoch 22/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - AUC: 0.8660 - loss: 0.2615\n",
      "Epoch 23/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - AUC: 0.8652 - loss: 0.2596\n",
      "Epoch 24/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - AUC: 0.8657 - loss: 0.2607\n",
      "Epoch 25/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 6ms/step - AUC: 0.8675 - loss: 0.2608\n",
      "Epoch 26/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - AUC: 0.8659 - loss: 0.2609\n",
      "Epoch 27/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7ms/step - AUC: 0.8664 - loss: 0.2612\n",
      "Epoch 28/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - AUC: 0.8660 - loss: 0.2612\n",
      "Epoch 29/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - AUC: 0.8659 - loss: 0.2614\n",
      "Epoch 30/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - AUC: 0.8654 - loss: 0.2598\n",
      "Epoch 31/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - AUC: 0.8647 - loss: 0.2620\n",
      "Epoch 32/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - AUC: 0.8651 - loss: 0.2629\n",
      "Epoch 33/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - AUC: 0.8644 - loss: 0.2607\n",
      "Epoch 34/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - AUC: 0.8667 - loss: 0.2604\n",
      "Epoch 35/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - AUC: 0.8657 - loss: 0.2634\n",
      "Epoch 36/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 8ms/step - AUC: 0.8655 - loss: 0.2596\n",
      "Epoch 37/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8ms/step - AUC: 0.8663 - loss: 0.2619\n",
      "Epoch 38/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - AUC: 0.8681 - loss: 0.2588\n",
      "Epoch 39/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - AUC: 0.8660 - loss: 0.2599\n",
      "Epoch 40/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - AUC: 0.8658 - loss: 0.2614\n",
      "Epoch 41/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step - AUC: 0.8668 - loss: 0.2608\n",
      "Epoch 42/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 8ms/step - AUC: 0.8654 - loss: 0.2588\n",
      "Epoch 43/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 8ms/step - AUC: 0.8673 - loss: 0.2594\n",
      "Epoch 44/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - AUC: 0.8624 - loss: 0.2629\n",
      "Epoch 45/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - AUC: 0.8663 - loss: 0.2604\n",
      "Epoch 46/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 7ms/step - AUC: 0.8648 - loss: 0.2600\n",
      "Epoch 47/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - AUC: 0.8656 - loss: 0.2630\n",
      "Epoch 48/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8673 - loss: 0.2603\n",
      "Epoch 49/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - AUC: 0.8649 - loss: 0.2617\n",
      "Epoch 50/50\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - AUC: 0.8670 - loss: 0.2610\n",
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step\n",
      "StackNN ROC AUC: 0.8669923909650116\n",
      "\n",
      "Model ROC AUC Scores:\n",
      "Logistic Regression: 0.8508000485942548\n",
      "Random Forest: 0.8365779567639171\n",
      "CatBoost: 0.8661055425228263\n",
      "LightGBM: 0.8648873790457765\n",
      "XGBoost: 0.8641579637975969\n",
      "\n",
      "StackNN ROC AUC: 0.8669923909650116\n"
     ]
    }
   ],
   "source": [
    "# 신경망 메타 모델 정의\n",
    "input_layer = Input(shape=(len(models),))\n",
    "dense1 = Dense(10, activation='relu')(input_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(dense1)\n",
    "\n",
    "meta_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "meta_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "# 메타 모델 학습\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "meta_model.fit(stacked_predictions, y, epochs=40, batch_size=32, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# StackNN ROC AUC 점수 계산\n",
    "meta_model_proba = meta_model.predict(stacked_predictions).ravel()\n",
    "stacknn_roc_auc = roc_auc_score(y, meta_model_proba)\n",
    "new_result = pd.DataFrame([{'name': 'StackNN', 'roc_auc': stacknn_roc_auc}])\n",
    "results_df = pd.concat([results_df, new_result], ignore_index=True)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Meta Model: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - AUC: 0.6817 - loss: 0.3682 - val_AUC: 0.8648 - val_loss: 0.2675\n",
      "Epoch 2/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8656 - loss: 0.2657 - val_AUC: 0.8641 - val_loss: 0.2649\n",
      "Epoch 3/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8657 - loss: 0.2631 - val_AUC: 0.8653 - val_loss: 0.2630\n",
      "Epoch 4/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8673 - loss: 0.2636 - val_AUC: 0.8654 - val_loss: 0.2623\n",
      "Epoch 5/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8667 - loss: 0.2613 - val_AUC: 0.8651 - val_loss: 0.2618\n",
      "Epoch 6/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - AUC: 0.8653 - loss: 0.2597 - val_AUC: 0.8651 - val_loss: 0.2616\n",
      "Epoch 7/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - AUC: 0.8680 - loss: 0.2590 - val_AUC: 0.8653 - val_loss: 0.2613\n",
      "Epoch 8/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - AUC: 0.8666 - loss: 0.2604 - val_AUC: 0.8651 - val_loss: 0.2611\n",
      "Epoch 9/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - AUC: 0.8674 - loss: 0.2581 - val_AUC: 0.8653 - val_loss: 0.2611\n",
      "Epoch 10/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - AUC: 0.8673 - loss: 0.2592 - val_AUC: 0.8653 - val_loss: 0.2610\n",
      "Epoch 11/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8663 - loss: 0.2599 - val_AUC: 0.8653 - val_loss: 0.2617\n",
      "Epoch 12/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8666 - loss: 0.2587 - val_AUC: 0.8652 - val_loss: 0.2612\n",
      "Epoch 13/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - AUC: 0.8670 - loss: 0.2592 - val_AUC: 0.8653 - val_loss: 0.2609\n",
      "Epoch 14/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - AUC: 0.8688 - loss: 0.2591 - val_AUC: 0.8653 - val_loss: 0.2609\n",
      "Epoch 15/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - AUC: 0.8657 - loss: 0.2592 - val_AUC: 0.8653 - val_loss: 0.2612\n",
      "Epoch 16/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8653 - loss: 0.2586 - val_AUC: 0.8653 - val_loss: 0.2612\n",
      "Epoch 17/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8673 - loss: 0.2612 - val_AUC: 0.8653 - val_loss: 0.2608\n",
      "Epoch 18/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8666 - loss: 0.2598 - val_AUC: 0.8653 - val_loss: 0.2609\n",
      "Epoch 19/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8661 - loss: 0.2597 - val_AUC: 0.8653 - val_loss: 0.2613\n",
      "Epoch 20/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8697 - loss: 0.2575 - val_AUC: 0.8654 - val_loss: 0.2610\n",
      "Epoch 21/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8640 - loss: 0.2621 - val_AUC: 0.8654 - val_loss: 0.2610\n",
      "Epoch 22/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8672 - loss: 0.2585 - val_AUC: 0.8654 - val_loss: 0.2607\n",
      "Epoch 23/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - AUC: 0.8661 - loss: 0.2609 - val_AUC: 0.8654 - val_loss: 0.2609\n",
      "Epoch 24/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - AUC: 0.8650 - loss: 0.2586 - val_AUC: 0.8653 - val_loss: 0.2608\n",
      "Epoch 25/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - AUC: 0.8684 - loss: 0.2583 - val_AUC: 0.8654 - val_loss: 0.2611\n",
      "Epoch 26/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8661 - loss: 0.2589 - val_AUC: 0.8654 - val_loss: 0.2607\n",
      "Epoch 27/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8666 - loss: 0.2605 - val_AUC: 0.8655 - val_loss: 0.2607\n",
      "Epoch 28/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8675 - loss: 0.2609 - val_AUC: 0.8654 - val_loss: 0.2611\n",
      "Epoch 29/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - AUC: 0.8675 - loss: 0.2590 - val_AUC: 0.8655 - val_loss: 0.2606\n",
      "Epoch 30/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - AUC: 0.8664 - loss: 0.2599 - val_AUC: 0.8656 - val_loss: 0.2607\n",
      "Epoch 31/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8658 - loss: 0.2611 - val_AUC: 0.8655 - val_loss: 0.2606\n",
      "Epoch 32/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - AUC: 0.8687 - loss: 0.2586 - val_AUC: 0.8655 - val_loss: 0.2607\n",
      "Epoch 33/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8665 - loss: 0.2605 - val_AUC: 0.8654 - val_loss: 0.2611\n",
      "Epoch 34/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8677 - loss: 0.2595 - val_AUC: 0.8655 - val_loss: 0.2606\n",
      "Epoch 35/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - AUC: 0.8682 - loss: 0.2606 - val_AUC: 0.8656 - val_loss: 0.2609\n",
      "Epoch 36/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8656 - loss: 0.2622 - val_AUC: 0.8656 - val_loss: 0.2609\n",
      "Epoch 37/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step - AUC: 0.8680 - loss: 0.2588 - val_AUC: 0.8654 - val_loss: 0.2606\n",
      "Epoch 38/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - AUC: 0.8687 - loss: 0.2600 - val_AUC: 0.8656 - val_loss: 0.2611\n",
      "Epoch 39/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8663 - loss: 0.2583 - val_AUC: 0.8655 - val_loss: 0.2610\n",
      "Epoch 40/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - AUC: 0.8663 - loss: 0.2619 - val_AUC: 0.8654 - val_loss: 0.2615\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Meta Model: 1it [10:00, 600.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - AUC: 0.7367 - loss: 0.3838 - val_AUC: 0.8687 - val_loss: 0.2665\n",
      "Epoch 2/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - AUC: 0.8645 - loss: 0.2670 - val_AUC: 0.8686 - val_loss: 0.2622\n",
      "Epoch 3/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8660 - loss: 0.2621 - val_AUC: 0.8690 - val_loss: 0.2610\n",
      "Epoch 4/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8647 - loss: 0.2621 - val_AUC: 0.8690 - val_loss: 0.2604\n",
      "Epoch 5/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8662 - loss: 0.2612 - val_AUC: 0.8689 - val_loss: 0.2601\n",
      "Epoch 6/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8638 - loss: 0.2644 - val_AUC: 0.8689 - val_loss: 0.2597\n",
      "Epoch 7/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - AUC: 0.8639 - loss: 0.2603 - val_AUC: 0.8687 - val_loss: 0.2597\n",
      "Epoch 8/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - AUC: 0.8663 - loss: 0.2641 - val_AUC: 0.8690 - val_loss: 0.2595\n",
      "Epoch 9/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8645 - loss: 0.2609 - val_AUC: 0.8687 - val_loss: 0.2593\n",
      "Epoch 10/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - AUC: 0.8658 - loss: 0.2591 - val_AUC: 0.8688 - val_loss: 0.2597\n",
      "Epoch 11/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - AUC: 0.8648 - loss: 0.2617 - val_AUC: 0.8690 - val_loss: 0.2593\n",
      "Epoch 12/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8667 - loss: 0.2608 - val_AUC: 0.8690 - val_loss: 0.2594\n",
      "Epoch 13/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - AUC: 0.8653 - loss: 0.2607 - val_AUC: 0.8689 - val_loss: 0.2590\n",
      "Epoch 14/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - AUC: 0.8661 - loss: 0.2614 - val_AUC: 0.8690 - val_loss: 0.2591\n",
      "Epoch 15/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - AUC: 0.8667 - loss: 0.2597 - val_AUC: 0.8690 - val_loss: 0.2593\n",
      "Epoch 16/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - AUC: 0.8648 - loss: 0.2617 - val_AUC: 0.8690 - val_loss: 0.2587\n",
      "Epoch 17/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8647 - loss: 0.2623 - val_AUC: 0.8691 - val_loss: 0.2590\n",
      "Epoch 18/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - AUC: 0.8669 - loss: 0.2610 - val_AUC: 0.8690 - val_loss: 0.2588\n",
      "Epoch 19/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - AUC: 0.8656 - loss: 0.2593 - val_AUC: 0.8690 - val_loss: 0.2587\n",
      "Epoch 20/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8640 - loss: 0.2608 - val_AUC: 0.8691 - val_loss: 0.2587\n",
      "Epoch 21/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8657 - loss: 0.2621 - val_AUC: 0.8691 - val_loss: 0.2587\n",
      "Epoch 22/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - AUC: 0.8649 - loss: 0.2628 - val_AUC: 0.8691 - val_loss: 0.2605\n",
      "Epoch 23/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - AUC: 0.8627 - loss: 0.2631 - val_AUC: 0.8690 - val_loss: 0.2586\n",
      "Epoch 24/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8666 - loss: 0.2614 - val_AUC: 0.8690 - val_loss: 0.2586\n",
      "Epoch 25/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8673 - loss: 0.2592 - val_AUC: 0.8691 - val_loss: 0.2586\n",
      "Epoch 26/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - AUC: 0.8658 - loss: 0.2626 - val_AUC: 0.8691 - val_loss: 0.2586\n",
      "Epoch 27/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8634 - loss: 0.2621 - val_AUC: 0.8691 - val_loss: 0.2587\n",
      "Epoch 28/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8649 - loss: 0.2603 - val_AUC: 0.8691 - val_loss: 0.2590\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Meta Model: 2it [15:39, 446.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.6646 - loss: 0.4103 - val_AUC: 0.8660 - val_loss: 0.2717\n",
      "Epoch 2/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8656 - loss: 0.2702 - val_AUC: 0.8664 - val_loss: 0.2663\n",
      "Epoch 3/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8646 - loss: 0.2668 - val_AUC: 0.8665 - val_loss: 0.2633\n",
      "Epoch 4/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8645 - loss: 0.2665 - val_AUC: 0.8673 - val_loss: 0.2623\n",
      "Epoch 5/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8676 - loss: 0.2608 - val_AUC: 0.8674 - val_loss: 0.2617\n",
      "Epoch 6/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - AUC: 0.8660 - loss: 0.2630 - val_AUC: 0.8670 - val_loss: 0.2614\n",
      "Epoch 7/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - AUC: 0.8654 - loss: 0.2632 - val_AUC: 0.8668 - val_loss: 0.2615\n",
      "Epoch 8/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - AUC: 0.8649 - loss: 0.2590 - val_AUC: 0.8674 - val_loss: 0.2616\n",
      "Epoch 9/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - AUC: 0.8660 - loss: 0.2626 - val_AUC: 0.8672 - val_loss: 0.2609\n",
      "Epoch 10/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8661 - loss: 0.2623 - val_AUC: 0.8669 - val_loss: 0.2608\n",
      "Epoch 11/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - AUC: 0.8660 - loss: 0.2621 - val_AUC: 0.8670 - val_loss: 0.2607\n",
      "Epoch 12/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - AUC: 0.8648 - loss: 0.2614 - val_AUC: 0.8670 - val_loss: 0.2606\n",
      "Epoch 13/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8652 - loss: 0.2612 - val_AUC: 0.8670 - val_loss: 0.2605\n",
      "Epoch 14/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8645 - loss: 0.2626 - val_AUC: 0.8669 - val_loss: 0.2605\n",
      "Epoch 15/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8655 - loss: 0.2615 - val_AUC: 0.8671 - val_loss: 0.2604\n",
      "Epoch 16/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8649 - loss: 0.2611 - val_AUC: 0.8670 - val_loss: 0.2606\n",
      "Epoch 17/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - AUC: 0.8663 - loss: 0.2612 - val_AUC: 0.8671 - val_loss: 0.2605\n",
      "Epoch 18/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8646 - loss: 0.2612 - val_AUC: 0.8670 - val_loss: 0.2602\n",
      "Epoch 19/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - AUC: 0.8668 - loss: 0.2631 - val_AUC: 0.8670 - val_loss: 0.2603\n",
      "Epoch 20/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8627 - loss: 0.2616 - val_AUC: 0.8669 - val_loss: 0.2602\n",
      "Epoch 21/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - AUC: 0.8662 - loss: 0.2591 - val_AUC: 0.8669 - val_loss: 0.2601\n",
      "Epoch 22/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8657 - loss: 0.2610 - val_AUC: 0.8669 - val_loss: 0.2604\n",
      "Epoch 23/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8645 - loss: 0.2606 - val_AUC: 0.8670 - val_loss: 0.2601\n",
      "Epoch 24/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - AUC: 0.8663 - loss: 0.2594 - val_AUC: 0.8671 - val_loss: 0.2602\n",
      "Epoch 25/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8677 - loss: 0.2580 - val_AUC: 0.8670 - val_loss: 0.2602\n",
      "Epoch 26/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8645 - loss: 0.2607 - val_AUC: 0.8670 - val_loss: 0.2602\n",
      "Epoch 27/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8654 - loss: 0.2617 - val_AUC: 0.8670 - val_loss: 0.2603\n",
      "Epoch 28/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8670 - loss: 0.2590 - val_AUC: 0.8671 - val_loss: 0.2602\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Meta Model: 3it [21:35, 405.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - AUC: 0.6123 - loss: 0.4049 - val_AUC: 0.8650 - val_loss: 0.2699\n",
      "Epoch 2/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8675 - loss: 0.2663 - val_AUC: 0.8645 - val_loss: 0.2663\n",
      "Epoch 3/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8658 - loss: 0.2646 - val_AUC: 0.8650 - val_loss: 0.2642\n",
      "Epoch 4/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8670 - loss: 0.2642 - val_AUC: 0.8653 - val_loss: 0.2629\n",
      "Epoch 5/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8657 - loss: 0.2619 - val_AUC: 0.8654 - val_loss: 0.2628\n",
      "Epoch 6/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8661 - loss: 0.2604 - val_AUC: 0.8654 - val_loss: 0.2619\n",
      "Epoch 7/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8661 - loss: 0.2615 - val_AUC: 0.8654 - val_loss: 0.2615\n",
      "Epoch 8/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8664 - loss: 0.2614 - val_AUC: 0.8654 - val_loss: 0.2614\n",
      "Epoch 9/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - AUC: 0.8645 - loss: 0.2639 - val_AUC: 0.8655 - val_loss: 0.2614\n",
      "Epoch 10/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8668 - loss: 0.2580 - val_AUC: 0.8656 - val_loss: 0.2611\n",
      "Epoch 11/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8676 - loss: 0.2613 - val_AUC: 0.8654 - val_loss: 0.2611\n",
      "Epoch 12/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - AUC: 0.8639 - loss: 0.2618 - val_AUC: 0.8656 - val_loss: 0.2615\n",
      "Epoch 13/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - AUC: 0.8660 - loss: 0.2618 - val_AUC: 0.8656 - val_loss: 0.2612\n",
      "Epoch 14/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8647 - loss: 0.2624 - val_AUC: 0.8655 - val_loss: 0.2611\n",
      "Epoch 15/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8671 - loss: 0.2577 - val_AUC: 0.8657 - val_loss: 0.2612\n",
      "Epoch 16/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8670 - loss: 0.2626 - val_AUC: 0.8654 - val_loss: 0.2612\n",
      "Epoch 17/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - AUC: 0.8651 - loss: 0.2600 - val_AUC: 0.8656 - val_loss: 0.2613\n",
      "Epoch 18/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8674 - loss: 0.2607 - val_AUC: 0.8656 - val_loss: 0.2610\n",
      "Epoch 19/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8678 - loss: 0.2596 - val_AUC: 0.8657 - val_loss: 0.2609\n",
      "Epoch 20/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - AUC: 0.8667 - loss: 0.2616 - val_AUC: 0.8656 - val_loss: 0.2612\n",
      "Epoch 21/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8665 - loss: 0.2605 - val_AUC: 0.8658 - val_loss: 0.2609\n",
      "Epoch 22/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8684 - loss: 0.2586 - val_AUC: 0.8657 - val_loss: 0.2609\n",
      "Epoch 23/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - AUC: 0.8640 - loss: 0.2622 - val_AUC: 0.8656 - val_loss: 0.2609\n",
      "Epoch 24/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8674 - loss: 0.2598 - val_AUC: 0.8656 - val_loss: 0.2608\n",
      "Epoch 25/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - AUC: 0.8657 - loss: 0.2620 - val_AUC: 0.8657 - val_loss: 0.2611\n",
      "Epoch 26/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - AUC: 0.8657 - loss: 0.2600 - val_AUC: 0.8656 - val_loss: 0.2609\n",
      "Epoch 27/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8689 - loss: 0.2579 - val_AUC: 0.8657 - val_loss: 0.2610\n",
      "Epoch 28/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8652 - loss: 0.2607 - val_AUC: 0.8656 - val_loss: 0.2609\n",
      "Epoch 29/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - AUC: 0.8647 - loss: 0.2633 - val_AUC: 0.8657 - val_loss: 0.2609\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Meta Model: 4it [28:24, 406.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - AUC: 0.6976 - loss: 0.3824 - val_AUC: 0.8646 - val_loss: 0.2676\n",
      "Epoch 2/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8654 - loss: 0.2668 - val_AUC: 0.8642 - val_loss: 0.2637\n",
      "Epoch 3/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - AUC: 0.8624 - loss: 0.2635 - val_AUC: 0.8658 - val_loss: 0.2625\n",
      "Epoch 4/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - AUC: 0.8647 - loss: 0.2624 - val_AUC: 0.8656 - val_loss: 0.2620\n",
      "Epoch 5/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - AUC: 0.8648 - loss: 0.2618 - val_AUC: 0.8655 - val_loss: 0.2617\n",
      "Epoch 6/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8652 - loss: 0.2631 - val_AUC: 0.8657 - val_loss: 0.2614\n",
      "Epoch 7/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1811s\u001b[0m 630ms/step - AUC: 0.8681 - loss: 0.2572 - val_AUC: 0.8657 - val_loss: 0.2614\n",
      "Epoch 8/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8669 - loss: 0.2586 - val_AUC: 0.8656 - val_loss: 0.2612\n",
      "Epoch 9/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8648 - loss: 0.2628 - val_AUC: 0.8657 - val_loss: 0.2610\n",
      "Epoch 10/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m980s\u001b[0m 338ms/step - AUC: 0.8665 - loss: 0.2594 - val_AUC: 0.8656 - val_loss: 0.2610\n",
      "Epoch 11/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8669 - loss: 0.2602 - val_AUC: 0.8657 - val_loss: 0.2608\n",
      "Epoch 12/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - AUC: 0.8654 - loss: 0.2649 - val_AUC: 0.8657 - val_loss: 0.2608\n",
      "Epoch 13/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - AUC: 0.8670 - loss: 0.2582 - val_AUC: 0.8657 - val_loss: 0.2621\n",
      "Epoch 14/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - AUC: 0.8661 - loss: 0.2607 - val_AUC: 0.8656 - val_loss: 0.2608\n",
      "Epoch 15/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - AUC: 0.8669 - loss: 0.2603 - val_AUC: 0.8657 - val_loss: 0.2606\n",
      "Epoch 16/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8638 - loss: 0.2629 - val_AUC: 0.8657 - val_loss: 0.2607\n",
      "Epoch 17/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - AUC: 0.8657 - loss: 0.2580 - val_AUC: 0.8656 - val_loss: 0.2606\n",
      "Epoch 18/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8664 - loss: 0.2589 - val_AUC: 0.8657 - val_loss: 0.2605\n",
      "Epoch 19/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - AUC: 0.8665 - loss: 0.2610 - val_AUC: 0.8659 - val_loss: 0.2606\n",
      "Epoch 20/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8671 - loss: 0.2600 - val_AUC: 0.8657 - val_loss: 0.2605\n",
      "Epoch 21/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8674 - loss: 0.2584 - val_AUC: 0.8657 - val_loss: 0.2606\n",
      "Epoch 22/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8686 - loss: 0.2572 - val_AUC: 0.8658 - val_loss: 0.2618\n",
      "Epoch 23/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - AUC: 0.8668 - loss: 0.2624 - val_AUC: 0.8658 - val_loss: 0.2604\n",
      "Epoch 24/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8665 - loss: 0.2601 - val_AUC: 0.8657 - val_loss: 0.2604\n",
      "Epoch 25/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8651 - loss: 0.2616 - val_AUC: 0.8656 - val_loss: 0.2604\n",
      "Epoch 26/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - AUC: 0.8663 - loss: 0.2580 - val_AUC: 0.8658 - val_loss: 0.2604\n",
      "Epoch 27/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - AUC: 0.8676 - loss: 0.2575 - val_AUC: 0.8658 - val_loss: 0.2606\n",
      "Epoch 28/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - AUC: 0.8658 - loss: 0.2588 - val_AUC: 0.8658 - val_loss: 0.2605\n",
      "Epoch 29/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - AUC: 0.8651 - loss: 0.2626 - val_AUC: 0.8657 - val_loss: 0.2604\n",
      "Epoch 30/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - AUC: 0.8676 - loss: 0.2594 - val_AUC: 0.8658 - val_loss: 0.2604\n",
      "Epoch 31/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - AUC: 0.8669 - loss: 0.2607 - val_AUC: 0.8659 - val_loss: 0.2604\n",
      "Epoch 32/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - AUC: 0.8684 - loss: 0.2596 - val_AUC: 0.8659 - val_loss: 0.2603\n",
      "Epoch 33/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - AUC: 0.8656 - loss: 0.2601 - val_AUC: 0.8660 - val_loss: 0.2604\n",
      "Epoch 34/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 8ms/step - AUC: 0.8652 - loss: 0.2609 - val_AUC: 0.8658 - val_loss: 0.2606\n",
      "Epoch 35/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - AUC: 0.8656 - loss: 0.2603 - val_AUC: 0.8658 - val_loss: 0.2605\n",
      "Epoch 36/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 8ms/step - AUC: 0.8682 - loss: 0.2611 - val_AUC: 0.8658 - val_loss: 0.2605\n",
      "Epoch 37/40\n",
      "\u001b[1m2877/2877\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 9ms/step - AUC: 0.8668 - loss: 0.2589 - val_AUC: 0.8659 - val_loss: 0.2604\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Meta Model: 5it [1:23:22, 1000.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3596/3596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 신경망 메타 모델 초기화\n",
    "meta_model_probas = np.zeros(X.shape[0])\n",
    "meta_features = np.zeros((X.shape[0], len(models)))\n",
    "\n",
    "for train_index, valid_index in tqdm(skf.split(meta_features, y), desc=\"Training Meta Model\"):\n",
    "    X_meta_train, X_meta_valid = stacked_predictions[train_index], stacked_predictions[valid_index]\n",
    "    y_meta_train, y_meta_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "    # 신경망 메타 모델 정의\n",
    "    input_layer = Input(shape=(len(models),))\n",
    "    dense1 = Dense(10, activation='relu')(input_layer)\n",
    "    output_layer = Dense(1, activation='sigmoid')(dense1)\n",
    "\n",
    "    meta_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    meta_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "    # 조기 종료 콜백 정의\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # 메타 모델 학습\n",
    "    meta_model.fit(X_meta_train, y_meta_train, epochs=40, batch_size=32, verbose=1, validation_data=(X_meta_valid, y_meta_valid), callbacks=[early_stopping])\n",
    "\n",
    "    # 메타 모델 예측\n",
    "    valid_meta_proba = meta_model.predict(X_meta_valid).ravel()\n",
    "    meta_model_probas[valid_index] = valid_meta_proba\n",
    "\n",
    "# StackNN ROC AUC 점수 계산\n",
    "meta_model_proba = meta_model.predict(stacked_predictions).ravel()\n",
    "\n",
    "# 최종 ROC AUC 점수 계산\n",
    "stacknn_roc_auc = roc_auc_score(y, meta_model_probas)\n",
    "new_result = pd.DataFrame([{'name': 'StackNN', 'roc_auc': stacknn_roc_auc}])\n",
    "results_df = pd.concat([results_df, new_result], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name   roc_auc\n",
      "0  Logistic Regression    0.8508\n",
      "1        Random Forest  0.836578\n",
      "2             CatBoost  0.866106\n",
      "3             LightGBM  0.864887\n",
      "4              XGBoost  0.864158\n",
      "5     StackNN(default)  0.866992\n",
      "6       StackNN(kfold)  0.866928\n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
