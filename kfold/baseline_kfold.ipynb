{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "train = pd.read_csv('/Users/jaesolshin/내 드라이브/2024-2/Google ML Bootcamp2024/data/playground1/train.csv')\n",
    "train = train.sample(frac=0.01, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fx/7qldcfl92nb_g9hqp_lrssxm0000gn/T/ipykernel_72274/2705497402.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2899125     1\n",
      "3854901     1\n",
      "7377384     1\n",
      "10901782    1\n",
      "8099641     1\n",
      "           ..\n",
      "7582229     1\n",
      "6945714     1\n",
      "2404410     1\n",
      "7484099     1\n",
      "700051      1\n",
      "Name: Driving_License, Length: 115048, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train.iloc[:,[1,3,4,5,6,7,9]] = train.iloc[:,[1,3,4,5,6,7,9]].astype('category')\n",
      "/var/folders/fx/7qldcfl92nb_g9hqp_lrssxm0000gn/T/ipykernel_72274/2705497402.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2899125     28.0\n",
      "3854901     28.0\n",
      "7377384     18.0\n",
      "10901782    37.0\n",
      "8099641     28.0\n",
      "            ... \n",
      "7582229     46.0\n",
      "6945714     33.0\n",
      "2404410     33.0\n",
      "7484099     46.0\n",
      "700051      30.0\n",
      "Name: Region_Code, Length: 115048, dtype: category\n",
      "Categories (53, float64): [0.0, 1.0, 2.0, 3.0, ..., 49.0, 50.0, 51.0, 52.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  train.iloc[:,[1,3,4,5,6,7,9]] = train.iloc[:,[1,3,4,5,6,7,9]].astype('category')\n",
      "/var/folders/fx/7qldcfl92nb_g9hqp_lrssxm0000gn/T/ipykernel_72274/2705497402.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2899125     0\n",
      "3854901     0\n",
      "7377384     0\n",
      "10901782    1\n",
      "8099641     1\n",
      "           ..\n",
      "7582229     1\n",
      "6945714     1\n",
      "2404410     0\n",
      "7484099     1\n",
      "700051      1\n",
      "Name: Previously_Insured, Length: 115048, dtype: category\n",
      "Categories (2, int64): [0, 1]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train.iloc[:,[1,3,4,5,6,7,9]] = train.iloc[:,[1,3,4,5,6,7,9]].astype('category')\n",
      "/var/folders/fx/7qldcfl92nb_g9hqp_lrssxm0000gn/T/ipykernel_72274/2705497402.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2899125     157.0\n",
      "3854901      13.0\n",
      "7377384     152.0\n",
      "10901782    152.0\n",
      "8099641     124.0\n",
      "            ...  \n",
      "7582229     152.0\n",
      "6945714     152.0\n",
      "2404410     152.0\n",
      "7484099     152.0\n",
      "700051      152.0\n",
      "Name: Policy_Sales_Channel, Length: 115048, dtype: category\n",
      "Categories (118, float64): [1.0, 3.0, 4.0, 7.0, ..., 158.0, 159.0, 160.0, 163.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  train.iloc[:,[1,3,4,5,6,7,9]] = train.iloc[:,[1,3,4,5,6,7,9]].astype('category')\n",
      "/var/folders/fx/7qldcfl92nb_g9hqp_lrssxm0000gn/T/ipykernel_72274/2705497402.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.17345607  0.10677456 -0.49335897 ... -1.02681099 -0.76008498\n",
      " -0.56004047]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train.iloc[:,[2,8,10]] = scaler.fit_transform(train.iloc[:,[2,8,10]])\n",
      "/var/folders/fx/7qldcfl92nb_g9hqp_lrssxm0000gn/T/ipykernel_72274/2705497402.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.47520046  1.01249614 -1.66271528 ... -0.52512538 -1.05016687\n",
      " -1.86273109]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train.iloc[:,[2,8,10]] = scaler.fit_transform(train.iloc[:,[2,8,10]])\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 범주형 변수를 팩터로 변환 (카테고리형)\n",
    "train.iloc[:,[1,3,4,5,6,7,9]] = train.iloc[:,[1,3,4,5,6,7,9]].astype('category')\n",
    "\n",
    "# 최소-최대 정규화 (Min-Max 스케일링)\n",
    "scaler = StandardScaler()\n",
    "train.iloc[:,[2,8,10]] = scaler.fit_transform(train.iloc[:,[2,8,10]])\n",
    "\n",
    "# 이분변수 생성: \"Annual_Premium\" == 2630.0 인 경우\n",
    "train['Annual_Premium_Binary'] = (train['Annual_Premium'] == 2630.0).astype('category')\n",
    "\n",
    "# 로그 변환된 \"Annual_Premium\" 변수 생성\n",
    "train['Annual_Premium_Log'] = np.where(train['Annual_Premium'] > 0, np.log1p(train['Annual_Premium']), 0)\n",
    "\n",
    "# 예측에 필요 없는 'id'와 'Annual_Premium' 변수를 드롭\n",
    "train = train.drop(columns=['id', 'Annual_Premium'])\n",
    "\n",
    "# 원-핫 인코딩 (One-Hot Encoding)\n",
    "category_columns = ['Gender', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Policy_Sales_Channel', 'Annual_Premium_Binary']\n",
    "train = pd.get_dummies(train, columns=category_columns, drop_first=True, dtype=int)\n",
    "\n",
    "# XGBoost에서 발생하는 문제 해결\n",
    "train.columns = train.columns.str.replace('[', '').str.replace(']', '').str.replace('<', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 리스트\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('CatBoost', CatBoostClassifier(random_state=42, verbose=0)),\n",
    "    ('LightGBM', LGBMClassifier(random_state=42)),\n",
    "    ('XGBoost', XGBClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "# 평가 지표 계산 함수\n",
    "def evaluate_model(y_true, y_pred, y_proba):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    TP = conf_matrix[1, 1]\n",
    "    FN = conf_matrix[1, 0]\n",
    "    TN = conf_matrix[0, 0]\n",
    "    FP = conf_matrix[0, 1]\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "    roc_auc = roc_auc_score(y_true, y_proba)\n",
    "\n",
    "    return {\n",
    "        'Confusion Matrix': conf_matrix.tolist(),\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Positive Recall': recall,\n",
    "        'Specificity': specificity,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': roc_auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression: 5it [00:18,  3.67s/it]\n",
      "Training Random Forest: 5it [02:42, 32.52s/it]\n",
      "Training CatBoost: 5it [02:30, 30.08s/it]\n",
      "Training LightGBM: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 11313, number of negative: 80725\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 803\n",
      "[LightGBM] [Info] Number of data points in the train set: 92038, number of used features: 122\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122917 -> initscore=-1.965096\n",
      "[LightGBM] [Info] Start training from score -1.965096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM: 1it [00:02,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 11313, number of negative: 80725\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 92038, number of used features: 123\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122917 -> initscore=-1.965096\n",
      "[LightGBM] [Info] Start training from score -1.965096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM: 2it [00:05,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 11312, number of negative: 80726\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 806\n",
      "[LightGBM] [Info] Number of data points in the train set: 92038, number of used features: 123\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122906 -> initscore=-1.965197\n",
      "[LightGBM] [Info] Start training from score -1.965197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM: 3it [00:09,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 11313, number of negative: 80726\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.254613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 807\n",
      "[LightGBM] [Info] Number of data points in the train set: 92039, number of used features: 124\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122915 -> initscore=-1.965108\n",
      "[LightGBM] [Info] Start training from score -1.965108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM: 4it [00:21,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 11313, number of negative: 80726\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 816\n",
      "[LightGBM] [Info] Number of data points in the train set: 92039, number of used features: 124\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.122915 -> initscore=-1.965108\n",
      "[LightGBM] [Info] Start training from score -1.965108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM: 5it [00:24,  4.82s/it]\n",
      "Training XGBoost: 5it [00:21,  4.23s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Positive Recall</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Model</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[20168, 14], [2824, 4]]</td>\n",
       "      <td>0.876662</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.999306</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.851574</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>184360     1\n",
       "294750     0\n",
       "9397603    1\n",
       "1227194...</td>\n",
       "      <td>[0.0952848723491479, 0.00032033116215664367, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[20161, 21], [2824, 4]]</td>\n",
       "      <td>0.876358</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.998959</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.851030</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>4123482     0\n",
       "53254       0\n",
       "5137627     0\n",
       "1022...</td>\n",
       "      <td>[0.00032023988035724055, 0.0002929728907044894...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[20170, 11], [2821, 8]]</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.999455</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>0.852002</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>2899125     0\n",
       "10901782    0\n",
       "5911933     0\n",
       "5169...</td>\n",
       "      <td>[0.32264754639342663, 0.00029161582772650496, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[20161, 20], [2825, 3]]</td>\n",
       "      <td>0.876353</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.849458</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3854901     0\n",
       "9356601     0\n",
       "9969942     0\n",
       "9835...</td>\n",
       "      <td>[0.25711251861437723, 0.1729949490237273, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[20162, 19], [2814, 14]]</td>\n",
       "      <td>0.876874</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>0.999059</td>\n",
       "      <td>0.009787</td>\n",
       "      <td>0.850723</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>7377384     0\n",
       "8099641     0\n",
       "1128905     0\n",
       "1023...</td>\n",
       "      <td>[0.16752872952877843, 0.0012602046393913658, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[19467, 715], [2390, 438]]</td>\n",
       "      <td>0.865059</td>\n",
       "      <td>0.379879</td>\n",
       "      <td>0.154880</td>\n",
       "      <td>0.964572</td>\n",
       "      <td>0.220045</td>\n",
       "      <td>0.838442</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>184360     1\n",
       "294750     0\n",
       "9397603    1\n",
       "1227194...</td>\n",
       "      <td>[0.01, 0.0, 0.26, 0.22, 0.14, 0.0, 0.0, 0.08, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[19424, 758], [2371, 457]]</td>\n",
       "      <td>0.864016</td>\n",
       "      <td>0.376132</td>\n",
       "      <td>0.161598</td>\n",
       "      <td>0.962442</td>\n",
       "      <td>0.226070</td>\n",
       "      <td>0.833862</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>4123482     0\n",
       "53254       0\n",
       "5137627     0\n",
       "1022...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.23, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[19470, 711], [2381, 448]]</td>\n",
       "      <td>0.865624</td>\n",
       "      <td>0.386540</td>\n",
       "      <td>0.158360</td>\n",
       "      <td>0.964769</td>\n",
       "      <td>0.224674</td>\n",
       "      <td>0.836639</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2899125     0\n",
       "10901782    0\n",
       "5911933     0\n",
       "5169...</td>\n",
       "      <td>[0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[19472, 709], [2368, 460]]</td>\n",
       "      <td>0.866270</td>\n",
       "      <td>0.393499</td>\n",
       "      <td>0.162659</td>\n",
       "      <td>0.964868</td>\n",
       "      <td>0.230173</td>\n",
       "      <td>0.834376</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3854901     0\n",
       "9356601     0\n",
       "9969942     0\n",
       "9835...</td>\n",
       "      <td>[0.37, 0.12, 0.04, 0.0, 0.35, 0.45, 0.43, 0.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[19445, 736], [2394, 434]]</td>\n",
       "      <td>0.863966</td>\n",
       "      <td>0.370940</td>\n",
       "      <td>0.153465</td>\n",
       "      <td>0.963530</td>\n",
       "      <td>0.217109</td>\n",
       "      <td>0.833686</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>7377384     0\n",
       "8099641     0\n",
       "1128905     0\n",
       "1023...</td>\n",
       "      <td>[0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.51, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[19978, 204], [2644, 184]]</td>\n",
       "      <td>0.876228</td>\n",
       "      <td>0.474227</td>\n",
       "      <td>0.065064</td>\n",
       "      <td>0.989892</td>\n",
       "      <td>0.114428</td>\n",
       "      <td>0.864684</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>184360     1\n",
       "294750     0\n",
       "9397603    1\n",
       "1227194...</td>\n",
       "      <td>[0.14043036396592984, 0.0004086122701851706, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[20005, 177], [2637, 191]]</td>\n",
       "      <td>0.877705</td>\n",
       "      <td>0.519022</td>\n",
       "      <td>0.067539</td>\n",
       "      <td>0.991230</td>\n",
       "      <td>0.119524</td>\n",
       "      <td>0.868741</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>4123482     0\n",
       "53254       0\n",
       "5137627     0\n",
       "1022...</td>\n",
       "      <td>[6.564578893436377e-05, 0.00016639362170857476...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[[20033, 148], [2644, 185]]</td>\n",
       "      <td>0.878661</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.065394</td>\n",
       "      <td>0.992666</td>\n",
       "      <td>0.117015</td>\n",
       "      <td>0.867173</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>2899125     0\n",
       "10901782    0\n",
       "5911933     0\n",
       "5169...</td>\n",
       "      <td>[0.42254377600327164, 5.628963003589128e-05, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[[20025, 156], [2612, 216]]</td>\n",
       "      <td>0.879699</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.076379</td>\n",
       "      <td>0.992270</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.865262</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>3854901     0\n",
       "9356601     0\n",
       "9969942     0\n",
       "9835...</td>\n",
       "      <td>[0.16885102291462442, 0.05218473323710743, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[[19979, 202], [2614, 214]]</td>\n",
       "      <td>0.877613</td>\n",
       "      <td>0.514423</td>\n",
       "      <td>0.075672</td>\n",
       "      <td>0.989991</td>\n",
       "      <td>0.131936</td>\n",
       "      <td>0.865176</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>7377384     0\n",
       "8099641     0\n",
       "1128905     0\n",
       "1023...</td>\n",
       "      <td>[0.25120190348531374, 0.0001227156298121796, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[[20085, 97], [2723, 105]]</td>\n",
       "      <td>0.877445</td>\n",
       "      <td>0.519802</td>\n",
       "      <td>0.037129</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.069307</td>\n",
       "      <td>0.863985</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>184360     1\n",
       "294750     0\n",
       "9397603    1\n",
       "1227194...</td>\n",
       "      <td>[0.10441723266142548, 0.00014303220229896937, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[[20101, 81], [2724, 104]]</td>\n",
       "      <td>0.878096</td>\n",
       "      <td>0.562162</td>\n",
       "      <td>0.036775</td>\n",
       "      <td>0.995987</td>\n",
       "      <td>0.069034</td>\n",
       "      <td>0.866876</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>4123482     0\n",
       "53254       0\n",
       "5137627     0\n",
       "1022...</td>\n",
       "      <td>[5.681170151457668e-05, 0.0001554300954203547,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[[20091, 90], [2724, 105]]</td>\n",
       "      <td>0.877705</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.037116</td>\n",
       "      <td>0.995540</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.866139</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>2899125     0\n",
       "10901782    0\n",
       "5911933     0\n",
       "5169...</td>\n",
       "      <td>[0.3727198341718974, 0.00021489814109127242, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[[20091, 90], [2707, 121]]</td>\n",
       "      <td>0.878439</td>\n",
       "      <td>0.573460</td>\n",
       "      <td>0.042786</td>\n",
       "      <td>0.995540</td>\n",
       "      <td>0.079631</td>\n",
       "      <td>0.863390</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>3854901     0\n",
       "9356601     0\n",
       "9969942     0\n",
       "9835...</td>\n",
       "      <td>[0.1155889508830457, 0.1806200137407985, 0.037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[[20061, 120], [2708, 120]]</td>\n",
       "      <td>0.877092</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.042433</td>\n",
       "      <td>0.994054</td>\n",
       "      <td>0.078227</td>\n",
       "      <td>0.864696</td>\n",
       "      <td>LightGBM</td>\n",
       "      <td>7377384     0\n",
       "8099641     0\n",
       "1128905     0\n",
       "1023...</td>\n",
       "      <td>[0.20226125337802828, 0.00017192771779513127, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[[19931, 251], [2599, 229]]</td>\n",
       "      <td>0.876141</td>\n",
       "      <td>0.477083</td>\n",
       "      <td>0.080976</td>\n",
       "      <td>0.987563</td>\n",
       "      <td>0.138452</td>\n",
       "      <td>0.862489</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>184360     1\n",
       "294750     0\n",
       "9397603    1\n",
       "1227194...</td>\n",
       "      <td>[0.116237536, 0.0002082086, 0.18743935, 0.1406...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[[20000, 182], [2616, 212]]</td>\n",
       "      <td>0.878401</td>\n",
       "      <td>0.538071</td>\n",
       "      <td>0.074965</td>\n",
       "      <td>0.990982</td>\n",
       "      <td>0.131595</td>\n",
       "      <td>0.866339</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>4123482     0\n",
       "53254       0\n",
       "5137627     0\n",
       "1022...</td>\n",
       "      <td>[0.00011588651, 0.00012447318, 0.00023501995, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[[19966, 215], [2652, 177]]</td>\n",
       "      <td>0.875402</td>\n",
       "      <td>0.451531</td>\n",
       "      <td>0.062566</td>\n",
       "      <td>0.989346</td>\n",
       "      <td>0.109904</td>\n",
       "      <td>0.863487</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>2899125     0\n",
       "10901782    0\n",
       "5911933     0\n",
       "5169...</td>\n",
       "      <td>[0.39893687, 9.5670206e-05, 0.0012468968, 8.61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[[19973, 208], [2593, 235]]</td>\n",
       "      <td>0.878265</td>\n",
       "      <td>0.530474</td>\n",
       "      <td>0.083098</td>\n",
       "      <td>0.989693</td>\n",
       "      <td>0.143687</td>\n",
       "      <td>0.862342</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>3854901     0\n",
       "9356601     0\n",
       "9969942     0\n",
       "9835...</td>\n",
       "      <td>[0.13896728, 0.13890766, 0.023013635, 0.000151...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[[19962, 219], [2612, 216]]</td>\n",
       "      <td>0.876961</td>\n",
       "      <td>0.496552</td>\n",
       "      <td>0.076379</td>\n",
       "      <td>0.989148</td>\n",
       "      <td>0.132394</td>\n",
       "      <td>0.861991</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>7377384     0\n",
       "8099641     0\n",
       "1128905     0\n",
       "1023...</td>\n",
       "      <td>[0.26540303, 0.00010495171, 0.00014944344, 9.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Confusion Matrix  Accuracy  Precision  Positive Recall  \\\n",
       "0      [[20168, 14], [2824, 4]]  0.876662   0.222222         0.001414   \n",
       "1      [[20161, 21], [2824, 4]]  0.876358   0.160000         0.001414   \n",
       "2      [[20170, 11], [2821, 8]]  0.876923   0.421053         0.002828   \n",
       "3      [[20161, 20], [2825, 3]]  0.876353   0.130435         0.001061   \n",
       "4     [[20162, 19], [2814, 14]]  0.876874   0.424242         0.004950   \n",
       "5   [[19467, 715], [2390, 438]]  0.865059   0.379879         0.154880   \n",
       "6   [[19424, 758], [2371, 457]]  0.864016   0.376132         0.161598   \n",
       "7   [[19470, 711], [2381, 448]]  0.865624   0.386540         0.158360   \n",
       "8   [[19472, 709], [2368, 460]]  0.866270   0.393499         0.162659   \n",
       "9   [[19445, 736], [2394, 434]]  0.863966   0.370940         0.153465   \n",
       "10  [[19978, 204], [2644, 184]]  0.876228   0.474227         0.065064   \n",
       "11  [[20005, 177], [2637, 191]]  0.877705   0.519022         0.067539   \n",
       "12  [[20033, 148], [2644, 185]]  0.878661   0.555556         0.065394   \n",
       "13  [[20025, 156], [2612, 216]]  0.879699   0.580645         0.076379   \n",
       "14  [[19979, 202], [2614, 214]]  0.877613   0.514423         0.075672   \n",
       "15   [[20085, 97], [2723, 105]]  0.877445   0.519802         0.037129   \n",
       "16   [[20101, 81], [2724, 104]]  0.878096   0.562162         0.036775   \n",
       "17   [[20091, 90], [2724, 105]]  0.877705   0.538462         0.037116   \n",
       "18   [[20091, 90], [2707, 121]]  0.878439   0.573460         0.042786   \n",
       "19  [[20061, 120], [2708, 120]]  0.877092   0.500000         0.042433   \n",
       "20  [[19931, 251], [2599, 229]]  0.876141   0.477083         0.080976   \n",
       "21  [[20000, 182], [2616, 212]]  0.878401   0.538071         0.074965   \n",
       "22  [[19966, 215], [2652, 177]]  0.875402   0.451531         0.062566   \n",
       "23  [[19973, 208], [2593, 235]]  0.878265   0.530474         0.083098   \n",
       "24  [[19962, 219], [2612, 216]]  0.876961   0.496552         0.076379   \n",
       "\n",
       "    Specificity  F1-Score       AUC                Model  \\\n",
       "0      0.999306  0.002811  0.851574  Logistic Regression   \n",
       "1      0.998959  0.002804  0.851030  Logistic Regression   \n",
       "2      0.999455  0.005618  0.852002  Logistic Regression   \n",
       "3      0.999009  0.002105  0.849458  Logistic Regression   \n",
       "4      0.999059  0.009787  0.850723  Logistic Regression   \n",
       "5      0.964572  0.220045  0.838442        Random Forest   \n",
       "6      0.962442  0.226070  0.833862        Random Forest   \n",
       "7      0.964769  0.224674  0.836639        Random Forest   \n",
       "8      0.964868  0.230173  0.834376        Random Forest   \n",
       "9      0.963530  0.217109  0.833686        Random Forest   \n",
       "10     0.989892  0.114428  0.864684             CatBoost   \n",
       "11     0.991230  0.119524  0.868741             CatBoost   \n",
       "12     0.992666  0.117015  0.867173             CatBoost   \n",
       "13     0.992270  0.135000  0.865262             CatBoost   \n",
       "14     0.989991  0.131936  0.865176             CatBoost   \n",
       "15     0.995194  0.069307  0.863985             LightGBM   \n",
       "16     0.995987  0.069034  0.866876             LightGBM   \n",
       "17     0.995540  0.069444  0.866139             LightGBM   \n",
       "18     0.995540  0.079631  0.863390             LightGBM   \n",
       "19     0.994054  0.078227  0.864696             LightGBM   \n",
       "20     0.987563  0.138452  0.862489              XGBoost   \n",
       "21     0.990982  0.131595  0.866339              XGBoost   \n",
       "22     0.989346  0.109904  0.863487              XGBoost   \n",
       "23     0.989693  0.143687  0.862342              XGBoost   \n",
       "24     0.989148  0.132394  0.861991              XGBoost   \n",
       "\n",
       "                                               y_true  \\\n",
       "0   184360     1\n",
       "294750     0\n",
       "9397603    1\n",
       "1227194...   \n",
       "1   4123482     0\n",
       "53254       0\n",
       "5137627     0\n",
       "1022...   \n",
       "2   2899125     0\n",
       "10901782    0\n",
       "5911933     0\n",
       "5169...   \n",
       "3   3854901     0\n",
       "9356601     0\n",
       "9969942     0\n",
       "9835...   \n",
       "4   7377384     0\n",
       "8099641     0\n",
       "1128905     0\n",
       "1023...   \n",
       "5   184360     1\n",
       "294750     0\n",
       "9397603    1\n",
       "1227194...   \n",
       "6   4123482     0\n",
       "53254       0\n",
       "5137627     0\n",
       "1022...   \n",
       "7   2899125     0\n",
       "10901782    0\n",
       "5911933     0\n",
       "5169...   \n",
       "8   3854901     0\n",
       "9356601     0\n",
       "9969942     0\n",
       "9835...   \n",
       "9   7377384     0\n",
       "8099641     0\n",
       "1128905     0\n",
       "1023...   \n",
       "10  184360     1\n",
       "294750     0\n",
       "9397603    1\n",
       "1227194...   \n",
       "11  4123482     0\n",
       "53254       0\n",
       "5137627     0\n",
       "1022...   \n",
       "12  2899125     0\n",
       "10901782    0\n",
       "5911933     0\n",
       "5169...   \n",
       "13  3854901     0\n",
       "9356601     0\n",
       "9969942     0\n",
       "9835...   \n",
       "14  7377384     0\n",
       "8099641     0\n",
       "1128905     0\n",
       "1023...   \n",
       "15  184360     1\n",
       "294750     0\n",
       "9397603    1\n",
       "1227194...   \n",
       "16  4123482     0\n",
       "53254       0\n",
       "5137627     0\n",
       "1022...   \n",
       "17  2899125     0\n",
       "10901782    0\n",
       "5911933     0\n",
       "5169...   \n",
       "18  3854901     0\n",
       "9356601     0\n",
       "9969942     0\n",
       "9835...   \n",
       "19  7377384     0\n",
       "8099641     0\n",
       "1128905     0\n",
       "1023...   \n",
       "20  184360     1\n",
       "294750     0\n",
       "9397603    1\n",
       "1227194...   \n",
       "21  4123482     0\n",
       "53254       0\n",
       "5137627     0\n",
       "1022...   \n",
       "22  2899125     0\n",
       "10901782    0\n",
       "5911933     0\n",
       "5169...   \n",
       "23  3854901     0\n",
       "9356601     0\n",
       "9969942     0\n",
       "9835...   \n",
       "24  7377384     0\n",
       "8099641     0\n",
       "1128905     0\n",
       "1023...   \n",
       "\n",
       "                                             y_scores  \n",
       "0   [0.0952848723491479, 0.00032033116215664367, 0...  \n",
       "1   [0.00032023988035724055, 0.0002929728907044894...  \n",
       "2   [0.32264754639342663, 0.00029161582772650496, ...  \n",
       "3   [0.25711251861437723, 0.1729949490237273, 0.00...  \n",
       "4   [0.16752872952877843, 0.0012602046393913658, 0...  \n",
       "5   [0.01, 0.0, 0.26, 0.22, 0.14, 0.0, 0.0, 0.08, ...  \n",
       "6   [0.0, 0.0, 0.0, 0.0, 0.0, 0.23, 0.0, 0.0, 0.0,...  \n",
       "7   [0.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.31, 0.0...  \n",
       "8   [0.37, 0.12, 0.04, 0.0, 0.35, 0.45, 0.43, 0.19...  \n",
       "9   [0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.51, 0.07...  \n",
       "10  [0.14043036396592984, 0.0004086122701851706, 0...  \n",
       "11  [6.564578893436377e-05, 0.00016639362170857476...  \n",
       "12  [0.42254377600327164, 5.628963003589128e-05, 0...  \n",
       "13  [0.16885102291462442, 0.05218473323710743, 0.0...  \n",
       "14  [0.25120190348531374, 0.0001227156298121796, 0...  \n",
       "15  [0.10441723266142548, 0.00014303220229896937, ...  \n",
       "16  [5.681170151457668e-05, 0.0001554300954203547,...  \n",
       "17  [0.3727198341718974, 0.00021489814109127242, 0...  \n",
       "18  [0.1155889508830457, 0.1806200137407985, 0.037...  \n",
       "19  [0.20226125337802828, 0.00017192771779513127, ...  \n",
       "20  [0.116237536, 0.0002082086, 0.18743935, 0.1406...  \n",
       "21  [0.00011588651, 0.00012447318, 0.00023501995, ...  \n",
       "22  [0.39893687, 9.5670206e-05, 0.0012468968, 8.61...  \n",
       "23  [0.13896728, 0.13890766, 0.023013635, 0.000151...  \n",
       "24  [0.26540303, 0.00010495171, 0.00014944344, 9.5...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교차 검증 설정\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "X = train.drop(columns=['Response'])\n",
    "y = train['Response']\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "results = []\n",
    "probas = []\n",
    "\n",
    "# 각 모델 학습 및 평가\n",
    "for name, model in models:\n",
    "    fold_metrics = []\n",
    "    fold_probas = []\n",
    "    for train_index, valid_index in tqdm(skf.split(X, y), desc=f\"Training {name}\"):\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "        # 모델 학습\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # 예측\n",
    "        valid_y_pred = model.predict(X_valid)\n",
    "        valid_y_proba = model.predict_proba(X_valid)[:, 1]  # 양성 클래스의 확률만 저장\n",
    "\n",
    "        # 평가\n",
    "        metrics = evaluate_model(y_valid, valid_y_pred, valid_y_proba)\n",
    "        metrics.update({\n",
    "            'Model': name,\n",
    "            'y_true': y_valid,\n",
    "            'y_scores': valid_y_proba\n",
    "        })\n",
    "        \n",
    "        fold_metrics.append(metrics)\n",
    "        fold_probas.append(valid_y_proba)\n",
    "\n",
    "    results.extend(fold_metrics)\n",
    "    probas.extend(fold_probas)\n",
    "\n",
    "# DataFrame 생성\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model       AUC\n",
      "0             CatBoost  0.866207\n",
      "1             LightGBM  0.865017\n",
      "2  Logistic Regression  0.850957\n",
      "3        Random Forest  0.835401\n",
      "4              XGBoost  0.863330\n"
     ]
    }
   ],
   "source": [
    "mean_auc_df = result_df.groupby('Model', as_index=False).mean()\n",
    "print(mean_auc_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
